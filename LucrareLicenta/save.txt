	Solutia propusa de mine desi se aseamana cu cea prezentata in Milner et al.(2019) \cite{multi-domain} din privinta folosirii mai multor baze de date si a metodei de clasificare, difera din mai multe privinte.\par 
					
					In primul rand, desi in implementarea mea folosesc mai multe baze de date, limba acestora difera (Spaniola, Germana, Italina, Engleza). Acest lucru afecteaza destul de puternic clasificatorul deoarece diferitele moduri de intonatii ale cuvintelor sau accentele specifice unei limbi pot avea o influenta asupra emotiei recunoscute. Pe langa asta, Milner et al.(2019) folosesc un set de date alcatuit din emotii naturale, tip de baza de date la care nu am avut acces, fiind limitat doar la cele constituite din emotii jucate.\par
					
					O alta diferenta arhitecturala este ca modelul meu este unul "end-to-end", lucru care face ca modul de extragere a datelor sa fie la randul lui antrenat in timpul invatarii, si sa nu fie bazat pe formule matematice ca in acest articol.  Avantajele folosirii acestui tip de extragere de caracteristici "automat" sunt prezentate in \ref{end-to-end2} si \ref{end-to-end}. \par
					
					Pe langa aceste doua diferente, cele doua arhitecturi incearca sa recunoasca doua seturi de emotii relativ diferite. Implemntarea mea clasifica patru tipuri de emotii: fericie, tristere, enervare si natural, in timp ce solutia din Milner et al.(2019) \cite{multi-domain} reuseste sa clasifice inca doua emotii frica si surprindere. Aceasta alegere de emotii clasificate depinde puternic de emotiile inregistrate in bazele de date folosite. \par
					
					Totusi cele doua implementari cad de acord cand vine vorba de importanta folosirii unui numar mai mare de baze de date, "multi-domain", pentru marirea generalitatii si combatarea numarului scazut de exemple in antrenarea modelelor SER. Acuratetea medie obtinuta in Milner et al.(2019) \cite{multi-domain} folosind antrenarea "multi-domain" este de 82\%. Desi cele doua procente sunt apropiate nu putem sa tragem concluzii puternice pe baza lor deoarece atat bazele de date folosite cat si emotiile clasificate difera. \par
					
					Antrenarea "Multi-domain" nu a fost totusi cea mai de succes metoda folosita in acest articol de cercetarea. Milner et al.(2019) \cite{multi-domain} propun si folisrea tehnicii numite "domain adversarial training", unde pe langa sarcina clasificarii emotiei, o parte din model a fost antrenata sa recunoasca si baza de date din care o inregistrarea face parte. Acest mecanism functioneaza ca un regularizator procesul de de calcularea a erorii, fiind adunat la eroarea rezultata din sarcina principala, SER. Prin introducerea acestui modul acuratetea modelului creste atingand, 82.26\%.
						
					\subsection{Improved End-to-End Speech Emotion Recognition Using Self Attention	Mechanism and Multitask Learning} \label{end-to-end2}
					
					Li, Yuanchao et al.(2019) \cite{yuan} au reusit sa obtina o acuratetea neponderata cu 14.3\% mai mare fata de solutiile tradionale prin metoda propusa. Aceata metoda se bazeaza pe conceptul de modele "end-to-end". Totusi arhitectura propusa se foloseste si de alte tehnici ca mecanismul de atentie si antrenare "multi-task" pentru a depasi unele obstacole in recunoasterea emotiilor in vorbire. \par
					
					Tehnica de extragere a caracteristicilor de intrare printr-un algoritm "machine learning" face ca toate modulele de procesare din interiorul modelului sa fie antrenabile. De aici apare si numele tehnicii, "end-to-end". Aceste modele sunt extrem de avantajoase in SER, obtinand rezultate incurajatoare \cite{adieu} \cite{e2e}. Folosirea unei astfel de extragere "automata", reduce cantitatea de imfluenta umana indusa in crearea modelului, deoarece nu mai necesita implicarea unor specialisti in domeniul audio pentru a determina cele mai eficente caracteristici de intrare. Pe langa acest motiv, nu exista un set fixat de caracteristici care sa extraga intr-un mod satisfacator informatiile emotionale din orice baza de date. \par
					
					Asemanator cu solutia propusa in Milner et al.(2019) \cite{multi-domain}, arhitectura foloseste doua nivele recurente bidirectionale la care s-a atasat un nivel de atentie si tehnica de  invatare "multi-task". Cu toate astea, cea de a doua sarcina pe care o executa clasificatorul nu mai este recunoasterea bazei de date ci a sexului persoanei care vorbeste in inregistrare. Prin folosirea acestui timp de antrenare clasificatorul are posibiltatea sa invete diferentele intre caracteristicile vocii unui vorbitor masculin si feminin. \par
					
					Modelul prezentat in acest articol stintific foloseste o singura baza de date de intrare. Astfel modelul devine specializat in a recunoaste emotii pe acel set de date, dar va da un randament mai slab in inferenta pe inregistrari din afara acestui set. Multimea de emotii clasificate este acelasi cu cea pe care il recunoaste si solutia proupsa de mine, obtinand o acuratete de 82.8\%, comparativ cu precizia de 68.5\% inregistrata folosind metodele traditionale pe aceasi baza de date.
					\subsection{Automatic speech emotion recognition using recurrent neural networks with local attention}
					 \label{prez_misramadi}
					 Misramadi et al. (2017) se focuseaza in articolul \cite{misramadi} pe evidentierea avantajului folosirii unei retele neruonale recurente urmata de un nivel de atentie pentru studiul recunoasterii de emotii in vorbire. Succesul folosirii retelelor recurente in domeniul SER a fost inregistrat in diferite solutii de alunglul anilor \cite{yuan}\cite{multi-domain}\cite{rnn1}\cite{rnn2}. Aceste rezultate prezinta cum prin folosirea unor retele recurente profunde, modelul poate sa invete atat sa recunoasca informatiile emotionale de scurta durata, per segment, cat si sa extraga relatile temporale dintre acestea intr-o perioada mai lunga de timp. \par
					 
					  \par 
					 Pe langa folosirea acestor retele neuronale ca modul principal de clasificare, Misramadi et al. (2017) propun folosirea unui mecanism de atentie bazat pe o suma ponderata (\ref{attention}). Ponderile acestui mecanism sunt la randul lor antrenate in procesul de invatare. In acest articol, aceasta tehnica este propusa ca o imbunatatire la arhiecturile traditionale ale sitemelor SER bazate pe retele recurente, fiind comparata cu alte modalitati mai putin de succes de combinare a emotiilor din segmentele semnalului audio pentru a obtine informatia emotionale totala per inregistrare. \par
					 
					 Celelalte modalitati care realizeaza aceasta sarcina sunt, recunoasterea emotiei in fiecare segment, folosirea inforatiei emotionale doar din ultimul segment si media informatiilor emotionale din toate segmentele. Aceste tehnici prezinta un numar de dezavantaje care sublineaza imporanta folosirii unui mecanism de atentie ponderat. In primul rand, nu este rezonabil sa asumam ca fiecare segment din inregistrarea audio contine informatie emotionala. Deoarece pauzele in vorbire si zgomotul de fundal au o frecventa mare in majoritatea inregistrarilor, modelul ar trebui sa fie cababil sa filtreze aceste segmente care pot sa ii dauneze acuratetii acestuia. Pe langa asta, asumarea ca ultimul segment continte informataia emotionala totala a semnalului audio este falsa deoarece daca informatia emotionala principala se afla la inceputul propozitiei (de exemplu un raset in prima secunda si apoi linisite pana la finalul inregistrarii) modelul va devia de la emotia recunoascuta atunci din cauza influentelor celorlalte segmente care se suprapun peste informatia emotionala initiala. Utilizarea operatiei de medie asupra intregului set de segmente nu este nici ea eficienta, deoarece segmentele lipsite in emotii vor continua sa aibe un efect asupra clasificarii. \par
					 
					 Din aceste motive, Misramadi et al. (2017) \cite{misramadi} propun folosirea unei sume ponderate, ponderile fiind invatae la antrenare, care va reusi sa determine segmentele bogate in emotii si sa isi indrepte atentia doar asupra acestora. Un astfel de mecanism de atentie am implementat si eu in aceasta lucrare de licenta, tehnica fiind prezenata in detaliu la sub-capitolul \ref{attention}.
					 
					 Solutia prezentata in acest articol foloseste o singura baza de date, extragerea datelor caracteristicilor este "hand-crafted", in contrast cu cea "end-to-end" folosita de mine, clasificatorul este alcatuit din doua nivele recurente BLSTM (\ref{RNN}),iar setul de emotii clasificate este acelasi cu cel folosit si de mine: fericire, tristete, enervare si neutru. Rezultatele obtinute in acest studiu depasesc cu 3.1\% acuratetea neponderata obtinuta in solutiile SER traditionale bazate pe alt tip de clasificator, SVM ("Support Vector Machine").
					 
				\subsection{Prezentare solutie propusa}
					Considerand diferitele obstacole ale domeniului recunoasterii emotiei in vorbire (\ref{obstacole}) si modalitati de implementare (\ref{papers}) mentionate anterior solutia pe care o propun in acest proiect este urmatoarea. \par
					
					Am decis sa folosesc un set de baze de date de intrare: 'EMO-DB', 'RAVDESS', 'EMOVO', 'MAV', 'ENTERFACE', 'JL', pentru a evita problema numarului scazut de exemple per set de date prezentata la 1.3.1. O problema rezultata in urma acestei decizi a fost ca diferentele dinte inregistrari sunt destule de mari, bazele de date contindand exemple in diferite limbi si moduri de inregistrare diferie. \par
					
					Pentru a reduce impactul acestui dezavantaj si pentru ca nu exista un set de caracteristici de intrare in SER considerat "corect", am decis sa folosesc o metoda antrenabila de extragere a informatie emotionale prin intermediul unei retele convolutionale adanci. In urma extragerii spectogramei Mel a fiecarui segment dintr-un semnal audio, \ref{mel}, valorile obtinute sunt normalizate pentru a reduce impactul discrepantelor dintre bazele de date. Valorile normalizate sunt apoi tranmise retelei neuronale convolutionale pentru extragerea datelor. Intre fiecare nivel din aceasta retea am introdus tehnica de "batch-normalization" pentru a reduce fenomenul de expolize al gradientilor, \ref{batch-norn}, si a grabi procesul de antrenare. Avantajele extragerii "automate" a caracteristicilor de intrare sunt prezentate mai sus in solutia propusa de Li, Yuanchao et al.(2019) \cite{yuan}. \par
					
					Modulul clasificator ales a fost bazat pe rationamentul din Misramadi et al. (2017) \cite{misramadi}, folosind astfel o retea neuronala recurenta cu celule BLSTM ("Bidirectional Long Short-Term Memory") pentru a profita de relatiile temporale dintre informatiile emotionale, urmat de un mecanism de atentie pentru ca modelul sa se focuseze doar pe segmentele bogate in emotie dintr-un semnal audio. \par
					
					Numarul de clase de emotii clasificate este patru, la fel ca in arhitecturile din Misramadi et al. (2017) \cite{misramadi} si	Li, Yuanchao et al.(2019) \cite{yuan}. Acuratetea maxima obtinuta folosind intregul set de baze de date enumarat mai sus este de 84.1\%, obtinand individual pe una dintre acstea , 'EMO-DB', si peste 90\%.  Aceste rezultate sunt asemanatoare cu cele din articolele prezentate mai sus, fiind printre cele mai ridicate momentan in domeniul SER. \par
					
					Proiectul meu contine si o interfata grafica care permite utilizatorului sa antreneze modelul folosind diferite configuratii, sa incarce noi inregistrari pentru a fi clasificate sau sa isi inregistreze propriile instante pentru inferenta prin interfata grafica. Aceasta interfata ofera si diferite statistici in timpul antrenarii pentru a permite utilizatorului sa observe in detaliu evolutia modelului in timp real la antrenare.\par				
				
					 In continuare urmeaza sa prezint in detaliu atat conceptele teoretice care stau la baza acestui proiect, in capitolul 4, dar si detaliile implementarii practice a solutiei propouse de mine, in capitolul 5.
